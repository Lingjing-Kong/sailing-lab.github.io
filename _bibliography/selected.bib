@inproceedings{
zheng2023judging,
title={Judging {LLM}-as-a-Judge with {MT}-Bench and Chatbot Arena},
author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
url={https://openreview.net/forum?id=uccHPGDlao}
}

@inproceedings {280874,
author = {Lianmin Zheng and Zhuohan Li and Hao Zhang and Yonghao Zhuang and Zhifeng Chen and Yanping Huang and Yida Wang and Yuanzhong Xu and Danyang Zhuo and Eric P. Xing and Joseph E. Gonzalez and Ion Stoica},
title = {Alpa: Automating Inter- and {Intra-Operator} Parallelism for Distributed Deep Learning},
booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},
year = {2022},
isbn = {978-1-939133-28-1},
address = {Carlsbad, CA},
pages = {559--578},
url = {https://www.usenix.org/conference/osdi22/presentation/zheng-lianmin},
publisher = {USENIX Association},
month = jul
}

@inbook{10.5555/3454287.3455230, author = {Wang, Haohan and Ge, Songwei and Xing, Eric P. and Lipton, Zachary C.}, title = {Learning robust global representations by penalizing local predictive power}, year = {2019}, publisher = {Curran Associates Inc.}, address = {Red Hook, NY, USA}, abstract = {Despite their well-documented predictive power on i.i.d. data, convolutional neural networks have been demonstrated to rely more on high-frequency (textural) patterns that humans deem superficial than on low-frequency patterns that agree better with intuitions about what constitutes category membership. This paper proposes a method for training robust convolutional networks by penalizing the predictive power of the local representations learned by earlier layers. Intuitively, our networks are forced to discard predictive signals such as color and texture that can be gleaned from local receptive fields and to rely instead on the global structure of the image. Across a battery of synthetic and benchmark domain adaptation tasks, our method confers improved generalization. To evaluate cross-domain transfer, we introduce ImageNet-Sketch, a new dataset consisting of sketch-like images and matching the ImageNet classification validation set in categories and scale.}, booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems}, articleno = {943}, numpages = {13} }


@inproceedings {273735,
author = {Aurick Qiao and Sang Keun Choe and Suhas Jayaram Subramanya and Willie Neiswanger and Qirong Ho and Hao Zhang and Gregory R. Ganger and Eric P. Xing},
title = {Pollux: Co-adaptive Cluster Scheduling for Goodput-Optimized Deep Learning},
booktitle = {15th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 21)},
year = {2021},
isbn = {978-1-939133-22-9},
pages = {1--18},
url = {https://www.usenix.org/conference/osdi21/presentation/qiao},
publisher = {{USENIX} Association},
month = jul
}

@misc{aragam2020identifiabilitynonparametricmixturemodels,
      title={Identifiability of Nonparametric Mixture Models and Bayes Optimal Clustering}, 
      author={Bryon Aragam and Chen Dan and Eric P. Xing and Pradeep Ravikumar},
      year={2020},
      eprint={1802.04397},
      archivePrefix={arXiv},
      primaryClass={math.ST},
      url={https://arxiv.org/abs/1802.04397}, 
}

@article{DBLP:journals/corr/abs-1901-08573,
  author       = {Hongyang Zhang and
                  Yaodong Yu and
                  Jiantao Jiao and
                  Eric P. Xing and
                  Laurent El Ghaoui and
                  Michael I. Jordan},
  title        = {Theoretically Principled Trade-off between Robustness and Accuracy},
  journal      = {CoRR},
  volume       = {abs/1901.08573},
  year         = {2019},
  url          = {http://arxiv.org/abs/1901.08573},
  eprinttype    = {arXiv},
  eprint       = {1901.08573},
  timestamp    = {Thu, 25 Aug 2022 08:42:42 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1901-08573.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.5555/3326943.3327130, author = {Kandasamy, Kirthevasan and Neiswanger, Willie and Schneider, Jeff and P\'{o}czos, Barnab\'{a}s and Xing, Eric P.}, title = {Neural architecture search with Bayesian optimisation and optimal transport}, year = {2018}, publisher = {Curran Associates Inc.}, address = {Red Hook, NY, USA}, abstract = {Bayesian Optimisation (BO) refers to a class of methods for global optimisation of a function f which is only accessible via point evaluations. It is typically used in settings where f is expensive to evaluate. A common use case for BO in machine learning is model selection, where it is not possible to analytically model the generalisation performance of a statistical model, and we resort to noisy and expensive training and validation procedures to choose the best model. Conventional BO methods have focused on Euclidean and categorical domains, which, in the context of model selection, only permits tuning scalar hyper-parameters of machine learning algorithms. However, with the surge of interest in deep learning, there is an increasing demand to tune neural network architectures. In this work, we develop NASBOT, a Gaussian process based BO framework for neural architecture search. To accomplish this, we develop a distance metric in the space of neural network architectures which can be computed efficiently via an optimal transport program. This distance might be of independent interest to the deep learning community as it may find applications outside of BO. We demonstrate that NASBOT outperforms other alternatives for architecture search in several cross validation based model selection tasks on multi-layer perceptrons and convolutional neural networks.}, booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems}, pages = {2020–2029}, numpages = {10}, location = {Montr\'{e}al, Canada}, series = {NIPS'18} }

@inproceedings{10.5555/3327546.3327618, author = {Zheng, Xun and Aragam, Bryon and Ravikumar, Pradeep and Xing, Eric P.}, title = {DAGs with NO TEARS: continuous optimization for structure learning}, year = {2018}, publisher = {Curran Associates Inc.}, address = {Red Hook, NY, USA}, abstract = {Estimating the structure of directed acyclic graphs (DAGs, also known as Bayesian networks) is a challenging problem since the search space of DAGs is combinatorial and scales superexponentially with the number of nodes. Existing approaches rely on various local heuristics for enforcing the acyclicity constraint. In this paper, we introduce a fundamentally different strategy: we formulate the structure learning problem as a purely continuous optimization problem over real matrices that avoids this combinatorial constraint entirely. This is achieved by a novel characterization of acyclicity that is not only smooth but also exact. The resulting problem can be efficiently solved by standard numerical algorithms, which also makes implementation effortless. The proposed method outperforms existing ones, without imposing any structural assumptions on the graph such as bounded treewidth or in-degree.}, booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems}, pages = {9492–9503}, numpages = {12}, location = {Montr\'{e}al, Canada}, series = {NIPS'18} }

@inproceedings{10.5555/3305381.3305545, author = {Hu, Zhiting and Yang, Zichao and Liang, Xiaodan and Salakhutdinov, Ruslan and Xing, Eric P.}, title = {Toward controlled generation of text}, year = {2017}, publisher = {JMLR.org}, booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70}, pages = {1587–1596}, numpages = {10}, location = {Sydney, NSW, Australia}, series = {ICML'17} }

@inproceedings{hu-etal-2016-harnessing,
    title = "Harnessing Deep Neural Networks with Logic Rules",
    author = "Hu, Zhiting  and
      Ma, Xuezhe  and
      Liu, Zhengzhong  and
      Hovy, Eduard  and
      Xing, Eric",
    editor = "Erk, Katrin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1228",
    doi = "10.18653/v1/P16-1228",
    pages = "2410--2420",
}

@article{XING2016179,
title = {Strategies and Principles of Distributed Machine Learning on Big Data},
journal = {Engineering},
volume = {2},
number = {2},
pages = {179-195},
year = {2016},
issn = {2095-8099},
doi = {https://doi.org/10.1016/J.ENG.2016.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S2095809916309468},
author = {Eric P. Xing and Qirong Ho and Pengtao Xie and Dai Wei},
keywords = {Machine learning, Artificial intelligence big data, Big model, Distributed systems, Principles, Theory, Data-parallelism, Model-parallelism}
}

@article{JMLR:v15:zhu14b,
  author  = {Jun Zhu and Ning Chen and Eric P. Xing},
  title   = {Bayesian Inference with Posterior Regularization and Applications to Infinite Latent SVMs},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {53},
  pages   = {1799--1847},
  url     = {http://jmlr.org/papers/v15/zhu14b.html}
}

@inproceedings{10.5555/3020751.3020816, author = {Neiswanger, Willie and Wang, Chong and Xing, Eric P.}, title = {Asymptotically exact, embarrassingly parallel MCMC}, year = {2014}, isbn = {9780974903910}, publisher = {AUAI Press}, address = {Arlington, Virginia, USA}, booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence}, pages = {623–632}, numpages = {10}, location = {Quebec City, Quebec, Canada}, series = {UAI'14} }

@inproceedings{10.5555/2999611.2999748, author = {Ho, Qirong and Cipar, James and Cui, Henggang and Kim, Jin Kyu and Lee, Seunghak and Gibbons, Phillip B. and Gibson, Garth A. and Ganger, Gregory R. and Xing, Eric P.}, title = {More effective distributed ML via a Stale Synchronous Parallel parameter server}, year = {2013}, publisher = {Curran Associates Inc.}, address = {Red Hook, NY, USA}, abstract = {We propose a parameter server system for distributed ML, which follows a Stale Synchronous Parallel (SSP) model of computation that maximizes the time computational workers spend doing useful work on ML algorithms, while still providing correctness guarantees. The parameter server provides an easy-to-use shared interface for read/write access to an ML model's values (parameters and variables), and the SSP model allows distributed workers to read older, stale versions of these values from a local cache, instead of waiting to get them from a central storage. This significantly increases the proportion of time workers spend computing, as opposed to waiting. Furthermore, the SSP model ensures ML algorithm correctness by limiting the maximum age of the stale values. We provide a proof of correctness under SSP, as well as empirical results demonstrating that the SSP model achieves faster algorithm convergence on several different ML problems, compared to fully-synchronous and asynchronous schemes.}, booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 1}, pages = {1223–1231}, numpages = {9}, location = {Lake Tahoe, Nevada}, series = {NIPS'13} }

@article{10.1214/12-AOAS549,
author = {Seyoung Kim and Eric P. Xing},
title = {{Tree-guided group lasso for multi-response regression with structured sparsity, with an application to eQTL mapping}},
volume = {6},
journal = {The Annals of Applied Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1095 -- 1117},
keywords = {eQTL analysis, genetic association mapping, high-dimensional regression, Lasso, structured sparsity},
year = {2012},
doi = {10.1214/12-AOAS549},
URL = {https://doi.org/10.1214/12-AOAS549}
}


@article{Kolar_2010,
   title={Estimating time-varying networks},
   volume={4},
   ISSN={1932-6157},
   url={http://dx.doi.org/10.1214/09-AOAS308},
   DOI={10.1214/09-aoas308},
   number={1},
   journal={The Annals of Applied Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Kolar, Mladen and Song, Le and Ahmed, Amr and Xing, Eric P.},
   year={2010},
   month=mar }


@inproceedings{Hanneke2006DiscreteTM,
  title={Discrete Temporal Models of Social Networks},
  author={Steve Hanneke and Eric P. Xing},
  booktitle={SNA@ICML},
  year={2006},
  url={https://api.semanticscholar.org/CorpusID:3176772}
}

@inproceedings{NIPS2008_8613985e,
 author = {Airoldi, Edo M and Blei, David and Fienberg, Stephen and Xing, Eric},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Mixed Membership Stochastic Blockmodels},
 url = {https://proceedings.neurips.cc/paper_files/paper/2008/file/8613985ec49eb8f757ae6439e879bb2a-Paper.pdf},
 volume = {21},
 year = {2008}
}

@inproceedings{NIPS2002_c3e4035a,
 author = {Xing, Eric and Jordan, Michael and Russell, Stuart J and Ng, Andrew},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Becker and S. Thrun and K. Obermayer},
 pages = {},
 publisher = {MIT Press},
 title = {Distance Metric Learning with Application to Clustering with Side-Information},
 url = {https://proceedings.neurips.cc/paper_files/paper/2002/file/c3e4035af2a1cde9f21e1ae1951ac80b-Paper.pdf},
 volume = {15},
 year = {2002}
}